services:
  eyestock-fastapi:
    build: .                      # Dockerfile 빌드 결과 사용
    container_name: eyestock-fastapi
#    gpus: all                     # GPU 활성화(= runtime/deploy 대체)-> ComposeV2에선 실행x
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NAVER_CLIENT_ID=ZdXlVrCKm3aVo2CK8HzC
      - NAVER_CLIENT_SECRET=fWGgWzZPhJ

      - MODEL_PATH=/llm1/models/llama-3.2
      - EMBEDDING_PATH=/llm1/models/embedding-e5

      - COIN_MODEL_PATH=/llm1/models/transformer_target5.pth

      - HF_HUB_OFFLINE=1

    working_dir: /llm1
    volumes:
      - ./:/llm1
      - ./vectorstore_data:/llm1/vectorstore_data          # (권장) 영속화
      - ./vectorstore_user_logs:/llm1/vectorstore_user_logs # (권장) 영속화
      - ./coin_predict_logs:/llm1/coin_predict_logs
      - ./vectorstore_data:/llm1/vectorstore_data
      - ./hf_cache:/root/.cache/huggingface
    ports:
      - "5050:8000"               # FastAPI 포트 노출
    stdin_open: true
    tty: true
#    command: /bin/bash            # 팀 방식 유지(진입 후 수동 설치/실행)
    restart: unless-stopped

